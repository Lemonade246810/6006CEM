# -*- coding: utf-8 -*-
"""CLASSIFICATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11sYWH9GGP7_mc1tpMCkf3GkA4dFS_g43
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.utils import class_weight
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
url = "flight_delays.csv"
df = pd.read_csv(url)

# Step 1: Data Preprocessing
# Handling missing values by dropping rows where 'DelayMinutes' is null since it's the target variable
df_clean = df.dropna(subset=['DelayMinutes'])

# Filling missing values for DelayReason
df_clean['DelayReason'].fillna('Unknown', inplace=True)

# Convert time-related columns into datetime format
df_clean['ScheduledDeparture'] = pd.to_datetime(df_clean['ScheduledDeparture'], errors='coerce')
df_clean['ActualDeparture'] = pd.to_datetime(df_clean['ActualDeparture'], errors='coerce')
df_clean['ScheduledArrival'] = pd.to_datetime(df_clean['ScheduledArrival'], errors='coerce')
df_clean['ActualArrival'] = pd.to_datetime(df_clean['ActualArrival'], errors='coerce')

# Feature engineering: Create delay features
df_clean['DepartureDelay'] = (df_clean['ActualDeparture'] - df_clean['ScheduledDeparture']).dt.total_seconds() / 60.0
df_clean['ArrivalDelay'] = (df_clean['ActualArrival'] - df_clean['ScheduledArrival']).dt.total_seconds() / 60.0

# Drop unnecessary columns
df_clean = df_clean.drop(columns=['ScheduledDeparture', 'ActualDeparture', 'ScheduledArrival', 'ActualArrival',
                                  'FlightID', 'FlightNumber', 'TailNumber'])

# Convert categorical variables to numeric via Label Encoding
label_cols = ['Airline', 'Origin', 'Destination', 'DelayReason', 'AircraftType', 'Cancelled', 'Diverted']
label_encoders = {}

for col in label_cols:
    df_clean[col] = df_clean[col].astype(str)
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col])
    label_encoders[col] = le

# Step 2: Classification Problem
# Define a binary classification target: Long delay (>30 mins) or short delay (<=30 mins)
df_clean['DelayCategory'] = df_clean['DelayMinutes'].apply(lambda x: 1 if x > 30 else 0)
X_clf = df_clean.drop(columns=['DelayMinutes', 'DelayCategory'])  # Features
y_clf = df_clean['DelayCategory']  # Target

# Remove low-variance features
selector = VarianceThreshold(threshold=0.01)
X_clf = selector.fit_transform(X_clf)

# Split the data into training and test sets
X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.3, random_state=42)

# Step 3: Feature Scaling for KNN
scaler = StandardScaler()
X_train_clf_scaled = scaler.fit_transform(X_train_clf)
X_test_clf_scaled = scaler.transform(X_test_clf)

# Step 4: Hyperparameter Tuning for Random Forest
param_dist = {
    'n_estimators': [100, 200, 500],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf_tuned_clf = RandomizedSearchCV(
    RandomForestClassifier(random_state=42, class_weight='balanced'),
    param_distributions=param_dist,
    n_iter=10,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

rf_tuned_clf.fit(X_train_clf, y_train_clf)
best_rf_clf = rf_tuned_clf.best_estimator_

# Predict and Evaluate Random Forest Classifier
y_pred_best_rf = best_rf_clf.predict(X_test_clf)
acc_rf_clf = accuracy_score(y_test_clf, y_pred_best_rf)
print("Tuned Random Forest Classifier Accuracy:", acc_rf_clf)
print(classification_report(y_test_clf, y_pred_best_rf))

# Feature importance visualization
importances = best_rf_clf.feature_importances_
feature_names = selector.get_feature_names_out()
plt.figure(figsize=(10, 6))
sns.barplot(x=importances, y=feature_names, palette="viridis")
plt.title("Random Forest Feature Importance")
plt.xlabel("Importance Score")
plt.ylabel("Features")
plt.tight_layout()
plt.show()

# Step 5: Train and Evaluate KNN Classifier
knn_clf = KNeighborsClassifier(n_neighbors=5)
knn_clf.fit(X_train_clf_scaled, y_train_clf)

y_pred_knn_clf = knn_clf.predict(X_test_clf_scaled)
acc_knn_clf = accuracy_score(y_test_clf, y_pred_knn_clf)
print(f"KNN Classifier Accuracy: {acc_knn_clf}")
print(classification_report(y_test_clf, y_pred_knn_clf))

# Confusion Matrices
conf_matrix_rf = confusion_matrix(y_test_clf, y_pred_best_rf)
conf_matrix_knn = confusion_matrix(y_test_clf, y_pred_knn_clf)

# Visualize Confusion Matrices
plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues')
plt.title("Random Forest Classifier Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")

plt.subplot(1, 2, 2)
sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Greens')
plt.title("KNN Classifier Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Step 6: Plot ROC Curves
# Ensure there are at least two classes in training and testing datasets
if len(np.unique(y_train_clf)) < 2 or len(np.unique(y_test_clf)) < 2:
    print("Error: Both classes (0 and 1) must be present in the dataset.")
else:
    y_pred_proba_rf = best_rf_clf.predict_proba(X_test_clf)
    y_pred_proba_knn = knn_clf.predict_proba(X_test_clf_scaled)

    # Ensure class probabilities exist for both classes
    if y_pred_proba_rf.shape[1] == 2:
        y_pred_proba_rf = y_pred_proba_rf[:, 1]
    else:
        print("Warning: Random Forest classifier has only one class in `predict_proba`.")

    if y_pred_proba_knn.shape[1] == 2:
        y_pred_proba_knn = y_pred_proba_knn[:, 1]
    else:
        print("Warning: KNN classifier has only one class in `predict_proba`.")

    # Calculate ROC metrics
    if y_pred_proba_rf.shape[0] > 0 and y_pred_proba_knn.shape[0] > 0:
        fpr_rf, tpr_rf, _ = roc_curve(y_test_clf, y_pred_proba_rf)
        fpr_knn, tpr_knn, _ = roc_curve(y_test_clf, y_pred_proba_knn)

        # Plot ROC curves
        plt.figure(figsize=(10, 6))
        plt.plot(fpr_rf, tpr_rf, label=f"Random Forest (AUC = {auc(fpr_rf, tpr_rf):.2f})", color='blue')
        plt.plot(fpr_knn, tpr_knn, label=f"KNN (AUC = {auc(fpr_knn, tpr_knn):.2f})", color='green')
        plt.plot([0, 1], [0, 1], 'k--', lw=1)
        plt.title("ROC Curve")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.legend()
        plt.tight_layout()
        plt.show()
    else:
        print("ROC curves could not be plotted due to lack of sufficient class probabilities.")